---
title: "OkCupid Final"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(data.table)
library(stringr)
library(ggplot2)
library(dplyr)
library(mice)
library(tidyr)
library(tidytext)

#Datacleaning OK Cupid----First Import and remplace blanks with "NA" and "-1" in Income category with "NA"
Data<-read.csv('profiles.csv', na.strings =c("","-1"))

#remove all essays but essay 5 "The six things I could never do without"
Data$essay0<-NULL
Data$essay1<-NULL
Data$essay2<-NULL
Data$essay3<-NULL
Data$essay4<-NULL
Data$essay6<-NULL
Data$essay7<-NULL
Data$essay8<-NULL
Data$essay9<-NULL
#remove variable "last online" information is NA to analysis
Data$last_online<-NULL



#remove rows with more than 7 (50% of optional responses) missing values using manual function 'delete.na'. 
delete.na <- function(DF, n=0) {
  DF[rowSums(is.na(DF)) <= n,]}

#59K before 
Data<-delete.na(Data, 7)
#56K Observations remaining 

#determine the percentage of missing values for each category 

NA_Percentage<-sort(sapply(Data, function(x) { 
  sum(is.na(x))/56236*100 }), decreasing=TRUE) 

NA_Percentage<-as.data.frame(NA_Percentage)

#variables with missing values greater than 30% of observations are removed from analysis. 
#This includes "income", "offspring", and "Diet
#one can assume data is MNAR (therefore MICE would not be approriate) 
#The variables should not be used in the analysis due to the % of missing observations.
#Income and Children are sensitive topics that people are reluctant to discuss publically. Therefore, questions are MNAR

Data$income<-NULL
Data$offspring<-NULL
Data$diet<-NULL

#18 variables remain

#cleaning data / formatting 
#replace "&rsquo;" in sign" category with "'"

Data$sign<-str_replace_all(Data$sign,"&rsquo;","'")

#replace "<<br/>" in essay 5 with " " 
Data$essay5<-str_replace_all(Data$essay5,"<br />"," ")

#review data structure
str(Data)

#update height to numeric category..Factor Variable Trap, must convert to character first 
Data$height<-as.numeric(as.character(Data$height))
#update sign to factor category
Data$sign<-as.factor(Data$sign)
#Make a Backup of Data before moving on with analysis 
Data_Backup<-Data

#view height and age summarys to indentify outliers
summary(Data$height)
summary(Data$age)
#identify outliers for height and age 
sum(Data$height<48)
sum(Data$height>84)
sum(Data$age>68)

#check summary of other variables 
summary(Data$drinks)
summary(Data$drugs)
summary(Data$education)
summary(Data$smokes)
summary(Data$body_type)
summary(Data$sign)
summary(Data$ethnicity)

#drinks, smoking, body type, and education are MCAR. Can perform MICE
#Drugs and Signs leaving as is.NA is approrpiate response for those variables

#create dataframe to compute missing values for drinks, smoking, body type, and education

imp_data<-cbind.data.frame(Data$drinks,Data$education,Data$smokes,Data$body_type)
str(imp_data)

#run MICE for missing data for Drinks, Drugs, Body Type and Smoking

imp_1<-mice(imp_data,1)
complete_imp<-mice::complete(imp_1,1)

#check for NA values on imp data
sum(is.na(imp_data))
sum(is.na(complete_imp))
#NA reduced from 13234 to 3260.
#put imp data into main dataset

Data$drinks<-complete_imp$`Data$drinks`
Data$education<-complete_imp$`Data$education`
Data$smokes<-complete_imp$`Data$smokes`
Data$body_type<-complete_imp$`Data$body_type`


#review new NA percentages after MICE
NA_Percentage_Imp_Complete<-sort(sapply(Data, function(x) { 
  sum(is.na(x))/56236*100 }), decreasing=TRUE)
#update as dataframe
NA_Percentage_Imp_Complete<-as.data.frame(NA_Percentage_Imp_Complete)
#MICE reduced Missing Data % for drinks,education,smokes, and body type to under 2% for each variable.
#Data is ready for analysis 

#make copy of Final cleaned data
Data_Final<-Data


#which words do men and women tend to use?
library(tidytext)
men.only <-
  Data %>%
  filter(sex == 'm')
women.only <-
  Data %>%
  filter(sex == 'f')

#tolower() changes all the letters to lowercase so ThiS and this are counted as one word
#strsplit() splits the string into individual strings be
#table() counts the frequency of each word
men.word.count <-
  data.frame(table(unlist(strsplit(tolower(men.only$essay5), " "))))
women.word.count <-
  data.frame(table(unlist(strsplit(tolower(women.only$essay5), " "))))

men.word.count %>%
  arrange(-Freq)

women.word.count %>%
  arrange(-Freq) 

men.word.count <-data.frame(table(unlist(strsplit(tolower(men.only$essay5), " "))))
#Renamed Var1 to Word because it was easier to understand structure using "Word"
colnames(men.word.count)[1] <- 'Word'
#gsub is a part of the stringr package. In this case, it's used to replace special characters in the set of strings. 
#[\n] is a line break, while [-], [[:punct:]], [0-9] are other special characters like punctuation and numerical digits. 
men.word.count$Word <- gsub("[\n]", "", men.word.count$Word)
men.word.count$Word <- gsub("-", "", men.word.count$Word)
men.word.count$Word <- gsub("[[:punct:]]", "", men.word.count$Word)
men.word.count$Word <- gsub("[0-9]", "", men.word.count$Word)
men.word.count <- men.word.count[men.word.count$Word != '', ]

men.word.table<-men.word.count %>%
  #The stop_words dataset in the tidytext package contains stop words (words to be filtered out, i.e prepositions and articles) from three lexicons. 
  #filter() to use only one set of stop words
  filter(!(Word %in% stop_words$word)) %>%
  arrange(-Freq) %>%
  top_n(10)
#Without taking the top_n, R creates a pretty useless plot of too many words. 

ggplot(men.word.table, aes(x = Word, y = Freq, fill = Word))+geom_bar(stat = "identity")+ labs(x = "Word", y = "How Frequently Word is Used", title ="Most Popular Words in Male OkCupid Profiles (Essay #5)")

women.word.count <- data.frame(table(unlist(strsplit(tolower(women.only$essay5), " "))))
colnames(women.word.count)[1] <- 'Word'
women.word.count$Word <- gsub("[\n]", "", women.word.count$Word)
women.word.count$Word <- gsub("-", "", women.word.count$Word)
women.word.count$Word <- gsub("[[:punct:]]", "", women.word.count$Word)
women.word.count$Word <- gsub("[0-9]", "", women.word.count$Word)
women.word.count <- women.word.count[women.word.count$Word != '', ]

women.word.table<-women.word.count %>%
filter(!(Word %in% stop_words$word)) %>%
arrange(-Freq) %>%
top_n(10)

ggplot(women.word.table, aes(x = Word, y = Freq, fill= Word))+ geom_bar(stat = "identity")+labs(x = "Word", y = "How Frequently Word is Used", title ="Most Popular Words in Female OkCupid Profiles (Essay #5)")

#Looking at the difference in use for men vs women
ggplot(Data) + geom_bar(aes(x= sex, fill= sex)) + 
  labs(title ="Amount of Female Users Compared to Male Users", x = "Sex", y = "Count")+ 
  theme(plot.title = element_text(hjust = 0.5))

#By what sexual orientation do male and female OkCupid members tend to identify?
ggplot(Data) + geom_bar(aes(x=sex, fill = orientation, position = "stack")) + ggtitle("Sexual Orientation Categorized by Sex") + scale_fill_manual(values=c("gold1", "darkorchid4", "darkslategray3"))

#3. What is the distribution of ethnicity and sex? 
Data %>%
   filter(!is.na(ethnicity)) %>%
     ggplot(aes(x= ethnicity, fill=sex)) + 
        geom_bar(stat="count") + coord_flip()+labs(x= "Ethnicity", y = "Amount of People", title = "Sex and Ethnicity of OkCupid Users")
```


